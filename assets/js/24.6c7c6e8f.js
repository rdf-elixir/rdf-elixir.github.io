(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{420:function(s,t,a){"use strict";a.r(t);var n=a(33),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h1",{attrs:{id:"lists"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lists"}},[s._v("#")]),s._v(" Lists")]),s._v(" "),a("p",[s._v("RDF lists can be represented with the "),a("code",[s._v("RDF.List")]),s._v(" structure.")]),s._v(" "),a("p",[s._v("An existing "),a("code",[s._v("RDF.List")]),s._v(" in a given graph can be created with "),a("code",[s._v("RDF.List.new")]),s._v(" or its alias "),a("code",[s._v("RDF.list")]),s._v(", passing it the head node of a list and the graph containing the statements constituting the list.")]),s._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[s._v("graph "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" \n  "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("new")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n     ~"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("B")]),s._v("<"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),s._v(">\n     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("first")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("rest")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("add")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n     "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),s._v("\n     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("first")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n     "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("rest")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nlist "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("List")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("new")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("~"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("B")]),s._v("<"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),s._v(">"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" graph"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),a("p",[s._v("If the given head node does not refer to a well-formed RDF list in the graph, "),a("code",[s._v("nil")]),s._v(" is returned.")]),s._v(" "),a("p",[s._v("An entirely new "),a("code",[s._v("RDF.List")]),s._v(" can be created with "),a("code",[s._v("RDF.List.from")]),s._v(" or "),a("code",[s._v("RDF.list")]),s._v(" and a native Elixir list or an Elixir "),a("code",[s._v("Enumerable")]),s._v(" with values of all types that are allowed for objects of statements (including nested lists).")]),s._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[s._v("list "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"foo"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("bar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ~"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("B")]),s._v("<bar"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),a("p",[s._v("If you want to add the graph statements to an existing graph, you can do that via the "),a("code",[s._v("graph")]),s._v(" option.")]),s._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[s._v("existing_graph "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("new")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("S")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("p"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("O")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("graph:")]),s._v(" existing_graph"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),a("p",[s._v("The "),a("code",[s._v("head")]),s._v(" option also allows to specify a custom node for the head of the list.")]),s._v(" "),a("p",[s._v("The function "),a("code",[s._v("RDF.List.values/1")]),s._v(" allows to get the values of a RDF list (including nested lists) as a native Elixir list.")]),s._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[s._v("iex"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"foo"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Bar")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ~"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("B")]),s._v("<bar"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("List")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("values\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n  ~"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("L")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"foo"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  ~"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),a("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Bar")]),s._v(">"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  ~"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("B")]),s._v("<bar"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("XSD")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("new")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("XSD")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("new")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])])])])}),[],!1,null,null,null);t.default=e.exports}}]);