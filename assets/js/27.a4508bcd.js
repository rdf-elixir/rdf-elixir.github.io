(window.webpackJsonp=window.webpackJsonp||[]).push([[27],{426:function(s,a,t){"use strict";t.r(a);var e=t(33),n=Object(e.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"namespaces-and-vocabularies"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#namespaces-and-vocabularies"}},[s._v("#")]),s._v(" Namespaces and vocabularies")]),s._v(" "),t("p",[s._v("RDF.ex supports modules which represent RDF vocabularies as "),t("code",[s._v("RDF.Vocabulary.Namespace")]),s._v("s, which allow for something similar to QNames in XML: an atom or function qualified with a "),t("code",[s._v("RDF.Vocabulary.Namespace")]),s._v(" can be resolved to an IRI. RDF.ex comes with predefined modules for some fundamental vocabularies defined in the "),t("code",[s._v("RDF.NS")]),s._v(" module.")]),s._v(" "),t("p",[s._v("There are two types of terms in a "),t("code",[s._v("RDF.Vocabulary.Namespace")]),s._v(" which are\nresolved differently:")]),s._v(" "),t("ol",[t("li",[s._v("Capitalized terms are by standard Elixir semantics module names, i.e.\natoms. At all places in RDF.ex where an IRI is expected, you can use atoms\nqualified with a "),t("code",[s._v("RDF.Vocabulary.Namespace")]),s._v(" instead. If you want to resolve them manually, you can pass a "),t("code",[s._v("RDF.Vocabulary.Namespace")]),s._v(" qualified atom to "),t("code",[s._v("RDF.iri")]),s._v(".")]),s._v(" "),t("li",[s._v("Lowercased terms for RDF properties are represented as functions on a\n"),t("code",[s._v("RDF.Vocabulary.Namespace")]),s._v(" module and return the IRI directly, but since "),t("code",[s._v("RDF.iri")]),s._v(" can also handle IRIs directly, you can safely and consistently use it with lowercased terms too.")])]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[s._v("iex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("only:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alias")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDFS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDFS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Class")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDFS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Class")]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("iri")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDFS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#Class>")]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDFS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("subClassOf\n~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#subClassOf>")]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("iri")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDFS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("subClassOf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#subClassOf>")]),s._v("\n")])])]),t("p",[s._v("As this example shows, the namespace modules can be easily "),t("code",[s._v("alias")]),s._v("ed. When required, they can be also aliased to a completely different name. Since the "),t("code",[s._v("RDF")]),s._v(" vocabulary namespace in "),t("code",[s._v("RDF.NS.RDF")]),s._v(" can't be aliased (it would clash with the top-level "),t("code",[s._v("RDF")]),s._v(" module), all of its elements can be accessed directly from the "),t("code",[s._v("RDF")]),s._v(" module without an alias.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[s._v("iex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("only:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("type\n~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1999")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("02")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("syntax"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("ns"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#type>")]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("iri")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1999")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("02")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("syntax"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("ns"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#Property>")]),s._v("\n")])])]),t("p",[s._v("This way of expressing IRIs has the additional benefit, that the existence of the referenced IRI is checked at compile time, i.e. whenever a term is used that is not part of the resp. vocabulary an error is raised by the Elixir compiler (unless the vocabulary namespace is non-strict; see below).")]),s._v(" "),t("p",[s._v("For terms not adhering to the capitalization rules (lowercase properties, capitalized non-properties) or containing characters not allowed within atoms, the predefined namespaces in "),t("code",[s._v("RDF.NS")]),s._v(" define aliases accordingly. If unsure, have a look at the documentation or their definitions.")]),s._v(" "),t("h2",{attrs:{id:"pattern-matching"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#pattern-matching"}},[s._v("#")]),s._v(" Pattern matching")]),s._v(" "),t("p",[s._v("You can't use terms from vocabulary namespaces in pattern matching expressions, since function calls are generally not allowed during pattern matches in Elixir. With the "),t("code",[s._v("term_to_iri/1")]),s._v(" macro from the "),t("code",[s._v("RDF.Namespace.IRI")]),s._v(" module, however, you can do just that. This macro is also automatically imported when you "),t("code",[s._v("use RDF")]),s._v(".")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# or an explicit: import RDF.Namespace.IRI")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("case")]),s._v(" expr "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("term_to_iri")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("...")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("term_to_iri")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("bar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("...")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("...")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("The predefined guards described in the "),t("a",{attrs:{href:"https://hexdocs.pm/rdf/RDF.Guards.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("API docs"),t("OutboundLink")],1),s._v(" are also useful in this context.")]),s._v(" "),t("h2",{attrs:{id:"defining-vocabulary-namespaces"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#defining-vocabulary-namespaces"}},[s._v("#")]),s._v(" Defining vocabulary namespaces")]),s._v(" "),t("p",[s._v("There are two basic ways to define a namespace for a vocabulary:")]),s._v(" "),t("ol",[t("li",[s._v("You can define all terms manually.")]),s._v(" "),t("li",[s._v("You can extract the terms from existing RDF data for IRIs of resources under the specified base IRI.")])]),s._v(" "),t("p",[s._v("It's recommended to introduce a dedicated module for the defined namespaces. In this module you'll "),t("code",[s._v("use RDF.Vocabulary.Namespace")]),s._v(" and define your vocabulary namespaces with the "),t("code",[s._v("defvocab")]),s._v(" macro.")]),s._v(" "),t("p",[s._v("A vocabulary namespace with manually defined terms can be defined as a list of atoms or strings with the "),t("code",[s._v("terms")]),s._v(" option like that:")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Vocabulary")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n\n  defvocab "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("base_iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://www.example.com/ns/"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("terms:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":Foo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":bar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n    \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("The "),t("code",[s._v("base_iri")]),s._v(" argument with the IRI prefix of all the terms in the defined\nvocabulary is required. Terms will be checked for invalid characters at compile-time and will raise a compiler error. This handling of invalid characters can be modified with the "),t("code",[s._v("invalid_characters")]),s._v(" options, which is set to "),t("code",[s._v(":fail")]),s._v(" by default. By setting it to "),t("code",[s._v(":warn")]),s._v(" only warnings will be raised or it can be turned off completely with "),t("code",[s._v(":ignore")]),s._v(".")]),s._v(" "),t("p",[s._v("A vocabulary namespace with extracted terms can be defined either by providing RDF data directly with the "),t("code",[s._v("data")]),s._v(" option or files with serialized RDF data in the "),t("code",[s._v("priv/vocabs")]),s._v(" directory using the "),t("code",[s._v("file")]),s._v(" option:")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("div",{staticClass:"highlight-lines"},[t("br"),t("br"),t("br"),t("br"),t("br"),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("br"),t("br"),t("br")]),t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Vocabulary")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n\n  defvocab "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("base_iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://www.example.com/ns/"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("file:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"your_vocabulary.nt"')]),s._v("\n    \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("During compilation the terms will be validated and checked for proper capitalisation by analyzing the schema description of the resp. resource  in the given data.\nThis validation behaviour can be modified with the "),t("code",[s._v("case_violations")]),s._v(" options, which supports the following values:")]),s._v(" "),t("ul",[t("li",[t("code",[s._v(":warn")]),s._v(": raises a warning on case violations (default)")]),s._v(" "),t("li",[t("code",[s._v(":fail")]),s._v(": raises an error on case violations")]),s._v(" "),t("li",[t("code",[s._v(":ignore")]),s._v(": ignores case violations")]),s._v(" "),t("li",[t("code",[s._v(":auto_fix")]),s._v(": fixes a case violation by automatically defining an alias with the proper casing of the first letter")]),s._v(" "),t("li",[s._v("an anonymous function or "),t("code",[s._v("{module, fun_name}")]),s._v(" tuple to an external function, which receives a "),t("code",[s._v(":resource")]),s._v(" or "),t("code",[s._v(":property")]),s._v(" atom and a case violated term and returns a properly cased alias in an ok tuple")])]),s._v(" "),t("p",[s._v("If your dealing with a lot of instance data with a lot of resources with lowercased term which you don't want to capitalize, you can set the "),t("code",[s._v("allow_lowercase_resource_terms")]),s._v(" option to "),t("code",[s._v("true")]),s._v(".")]),s._v(" "),t("p",[s._v("Invalid characters or violations of capitalization rules can be fixed by defining aliases for these terms with the "),t("code",[s._v("alias")]),s._v(" option and a keyword list where the keys are alias and the value the aliased terms as an atom or string:")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("div",{staticClass:"highlight-lines"},[t("br"),t("br"),t("br"),t("br"),t("br"),t("br"),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("br"),t("br"),t("br")]),t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Vocabulary")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n\n  defvocab "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("base_iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://www.example.com/ns/"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("file:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"your_vocabulary.nt"')]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("alias:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("example_term:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"example-term"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("When defining a vocabulary namespace manually over the "),t("code",[s._v("terms")]),s._v(" option, you can also define the aliases within the list of terms. So instead of having to repeat the aliased term in a definition like this:")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("div",{staticClass:"highlight-lines"},[t("br"),t("br"),t("br"),t("br"),t("br"),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("br"),t("br")]),t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Vocabulary")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n\n  defvocab "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("base_iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://www.example.com/ns/"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("terms:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Foo-bar"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Baz"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("alias:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FooBar")]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Foo-bar"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("You can define the same vocabulary namespace like this:")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("div",{staticClass:"highlight-lines"},[t("br"),t("br"),t("br"),t("br"),t("br"),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("br"),t("br")]),t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Vocabulary")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n\n  defvocab "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("base_iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://www.example.com/ns/"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("terms:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":Baz")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FooBar")]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Foo-bar"')]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("The "),t("code",[s._v("terms")]),s._v(" option can be used also in conjunction with the "),t("code",[s._v("file")]),s._v(" and "),t("code",[s._v("data")]),s._v(" option, but is having a different semantics in this case: it restricts the terms loaded from the vocabulary data to the specified ones.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("div",{staticClass:"highlight-lines"},[t("br"),t("br"),t("br"),t("br"),t("br"),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("br"),t("br")]),t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Vocabulary")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n\n  defvocab "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("base_iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://www.example.com/ns/"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("file:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"your_vocabulary.ttl"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("terms:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":Baz")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FooBar")]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Foo-bar"')]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("You can also provide an anonymous function or a "),t("code",[s._v("{module, fun_name}")]),s._v(" tuple to an external function to process the terms from the "),t("code",[s._v(":file")]),s._v(" or "),t("code",[s._v(":data")]),s._v(" vocabulary definitions. The function receives two arguments: either the "),t("code",[s._v(":property")]),s._v(" or "),t("code",[s._v(":resource")]),s._v(" classifying the reference of the term and a term as a string. It must return one of the following results:")]),s._v(" "),t("ul",[t("li",[s._v("an "),t("code",[s._v("{:ok, term}")]),s._v(" tuple, where "),t("code",[s._v("term")]),s._v(" is either the given term unchanged or another term which should be used as an alias for the given term")]),s._v(" "),t("li",[t("code",[s._v(":ignore")]),s._v(", if the given term should be ignored")]),s._v(" "),t("li",[s._v("an "),t("code",[s._v("{:error, error}")]),s._v(" tuple, which will result in an error for the given term in the error report")]),s._v(" "),t("li",[s._v("an "),t("code",[s._v("{:abort, error}")]),s._v(" tuple, which will result in an abortion of the vocabulary namespace creation with the given "),t("code",[s._v("error")]),s._v(" raised")])]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Vocabulary")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# We're using the ReCase library in this example")]),s._v("\n\n  defvocab "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("base_iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://www.example.com/ns/"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("file:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"your_vocabulary.ttl"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("terms:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("fn")]),s._v(" \n      _"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"_"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v(" _     "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":ignore")]),s._v("\n      _"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"erroneous"')]),s._v("  "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":error")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"erroneous term"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":resource")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" term "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":ok")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Recase")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("to_pascal")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("term"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" term "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":ok")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Recase")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("to_snake")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("term"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("When your term handler function is defined externally, you can refer to this function with an "),t("code",[s._v("{module, fun_name}")]),s._v(" tuple. But you can also add an additional argument in a "),t("code",[s._v("{module, fun_name, arguments}")]),s._v(" tuple, which can be handy when you want have a common term mapping module. In that case the function is expected to have as many additional arguments as the "),t("code",[s._v("arguments")]),s._v(" list contains.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Vocabulary")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n\n  defvocab "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("base_iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://www.example.com/ns/"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("file:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"your_vocabulary.ttl"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("terms:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("TermHandler")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":handle_term")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":variant1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("TermHandler")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("handle_term")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("type"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" term"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" variant "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("\\\\")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":variant1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("handle_term")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"_"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v(" _"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" _"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("do:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":ignore")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("handle_term")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":resource")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" term"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" _"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("do:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":ok")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Recase")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("to_pascal")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("term"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("handle_term")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" term"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":variant1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("do:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":ok")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Recase")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("to_snake")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("term"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("handle_term")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" term"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":variant2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("do:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":ok")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Recase")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("to_camel")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("term"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("If you just want to ignore a couple terms, you can also do that with the "),t("code",[s._v(":ignore")]),s._v(" option:")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("div",{staticClass:"highlight-lines"},[t("br"),t("br"),t("br"),t("br"),t("br"),t("br"),t("div",{staticClass:"highlighted"},[s._v(" ")]),t("br"),t("br"),t("br")]),t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Vocabulary")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n\n  defvocab "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("base_iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://www.example.com/ns/"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("file:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"your_vocabulary.nt"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("ignore:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("~w[Foo bar]")]),s._v("\n    \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("Though strongly discouraged, a vocabulary namespace can be defined as non-strict with the "),t("code",[s._v("strict")]),s._v(" option set to "),t("code",[s._v("false")]),s._v(". A non-strict vocabulary doesn't require any terms to be defined (although they can). A term is resolved dynamically at runtime by concatenation of the term and the base IRI of the resp. namespace module:")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Vocabulary")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n\n  defvocab "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("base_iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://www.example.com/ns/"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("terms:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("strict:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("only:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alias")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("iri")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("ns"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),s._v(">\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("bar\n~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("ns"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("bar"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("bar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Baz")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#RDF.Description<")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),s._v(">\n      "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("bar"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Baz")]),s._v("> "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n")])])]),t("div",{staticClass:"custom-block warning"},[t("p",{staticClass:"custom-block-title"},[s._v("WARNING")]),s._v(" "),t("p",[s._v("Non-strict vocabularies can't provide compile-time checks. For this reason, their usage is not recommended in production code. A typical usage scenario are tests for example.")]),s._v(" "),t("p",[s._v("Unfortunately, the compiler Elixir generally raises warnings when using the property functions of a non-strict vocabulary namespace. In order to get rid of this warnings, you have add the following compiler attribute in modules calling such property functions:")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@compile")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":no_warn_undefined")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NonStrictVocab")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])])]),t("p",[s._v("Since the underlying Erlang feature for this is a bit controversial in Elixir, it seems "),t("a",{attrs:{href:"https://github.com/elixir-lang/elixir/issues/11922",target:"_blank",rel:"noopener noreferrer"}},[s._v("this issue"),t("OutboundLink")],1),s._v(" won't be fixed. If someone knows a workaround for this, a PR would be very welcome.")])]),s._v(" "),t("h2",{attrs:{id:"vocabulary-namespace-metadata"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#vocabulary-namespace-metadata"}},[s._v("#")]),s._v(" Vocabulary namespace metadata")]),s._v(" "),t("p",[s._v("Every "),t("code",[s._v("RDF.Vocabulary.Namespace")]),s._v(" module has a couple of special metadata functions about the vocabulary itself. The most important ones are "),t("code",[s._v("__base_iri__/0")]),s._v(", "),t("code",[s._v("__iris__/0")]),s._v(" and "),t("code",[s._v("__file__/0")]),s._v(".")]),s._v(" "),t("p",[s._v("The "),t("code",[s._v("__base_iri__/0")]),s._v(" function returns the base IRI of the vocabulary namespace and the "),t("code",[s._v("__iris__/0")]),s._v(" function all IRIs which can be referenced with this namespace.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[s._v("iex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDFS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__base_iri__\n"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://www.w3.org/2000/01/rdf-schema#"')]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDFS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__iris__\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#Class>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#Container>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#ContainerMembershipProperty>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#Datatype>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#Literal>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#Resource>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#comment>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#domain>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#isDefinedBy>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#label>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#member>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#range>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#seeAlso>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#subClassOf>,")]),s._v("\n ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#subPropertyOf>]")]),s._v("\n")])])]),t("p",[s._v("The "),t("code",[s._v("__file__/0")]),s._v(" function returns the path to the file from which the vocabulary namespace was created from with the "),t("code",[s._v(":file")]),s._v(" option. This allows you to get easy access to all vocabulary descriptions you're using in your application via vocabulary namespaces, including those from libraries your application is using.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[s._v("iex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDFS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__file__\n"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"/local-path/your-app/_build/dev/lib/rdf/priv/vocabs/rdfs.ttl"')]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("read_file")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDFS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__file__"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":ok")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#RDF.Graph<name: nil")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("dc:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("purl"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("org"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("dc"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("elements")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.1")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("> "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("owl:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2002")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("owl"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#> .")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("rdf:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1999")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("02")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("syntax"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("ns"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#> .")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("rdfs:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#> .")]),s._v("\n\n  rdfs"),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":Class")]),s._v("\n      a rdfs"),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":Class")]),s._v(" ;\n      rdfs"),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":label")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Class"')]),s._v(" ;\n      rdfs"),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":comment")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"The class of classes."')]),s._v(" ;\n      rdfs"),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":isDefinedBy")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("rdfs:")]),s._v(" ;\n      rdfs"),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":subClassOf")]),s._v(" rdfs"),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":Resource")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("...")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])])]),t("h2",{attrs:{id:"namespaces"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#namespaces"}},[s._v("#")]),s._v(" Namespaces")]),s._v(" "),t("p",[t("code",[s._v("RDF.Vocabulary.Namespace")]),s._v("s are in fact just a special case of a more general concept in RDF.ex: "),t("code",[s._v("RDF.Namespace")]),s._v("s, which are modules acting as namespaces for terms that can be resolved to IRIs. But a "),t("code",[s._v("RDF.Namespace")]),s._v(" should not be confused with a IRI namespace. The terms of a "),t("code",[s._v("RDF.Namespace")]),s._v(' don\'t have to necessarily refer to IRIs from the same IRI namespace. "Namespace" here is just meant in the sense that an Elixir module is a namespace. Think of them more like the context of JSON-LD, where all terms for the IRIs in the context can be accessed via the same module namespace.')]),s._v(" "),t("p",[s._v("A "),t("code",[s._v("RDF.Namespace")]),s._v(" can be defined with the "),t("code",[s._v("defnamespace")]),s._v(" macro, which expects the module name and a keyword list or map of terms and their corresponding IRIs.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n  \n  defnamespace "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n                 "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("foo:")]),s._v(" ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("foo"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                 "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Bar")]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://example2.com/Bar"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n               "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("A "),t("code",[s._v("RDF.Namespace")]),s._v(" can be used similarly to "),t("code",[s._v("RDF.Namespace.Vocabulary")]),s._v(".")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[s._v("iex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("only:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alias")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("YourApp")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("foo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("foo"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("iri")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("foo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("foo"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n\niex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("iri")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Bar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Bar")]),s._v(">\n")])])]),t("h2",{attrs:{id:"namespace-delegator-modules"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#namespace-delegator-modules"}},[s._v("#")]),s._v(" Namespace delegator modules")]),s._v(" "),t("p",[s._v("Sometimes you want that modules of your application act as namespace modules.\nFor example, when you are developing an application for which you have defined a dedicated vocabulary, you may not want to have a separate namespace for the vocabulary with the same name and provoke naming conflicts or confusion between the application and the RDF namespace module. In such cases, you can define a "),t("code",[s._v("RDF.Namespace")]),s._v(" or "),t("code",[s._v("RDF.Vocabulary.Namespace")]),s._v(" and specify with the "),t("code",[s._v("RDF.Namespace.act_as_namespace/1")]),s._v(" macro, that another module should act as the specified RDF namespace.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Example")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Vocabulary")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n\n  defvocab "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Example")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("base_iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://www.example.com/ns/"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("terms:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":Foo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":bar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defmodule")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Example")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Namespace")]),s._v("\n\n  act_as_namespace "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Example")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Example")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# your application functions")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("This definition allows you to use the "),t("code",[s._v("Example")]),s._v(" module with your application functions as a full replacement for the "),t("code",[s._v("Example.NS.Example")]),s._v(" vocabulary namespace:")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[s._v("iex"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Example")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Example")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("bar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("42")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#RDF.Description<subject: ~I<http://www.example.com/ns/Foo>")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("ns"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),s._v(">\n      "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("ns"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("bar"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("42")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n")])])]),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),t("p",[s._v("The definition of a "),t("code",[s._v("RDF.Namespace")]),s._v(" can be very useful in this context, when your application vocabulary spans multiple URI namespaces.")])]),s._v(" "),t("div",{staticClass:"custom-block warning"},[t("p",{staticClass:"custom-block-title"},[s._v("WARNING")]),s._v(" "),t("p",[s._v("Be aware that this also defines the functions for the lowercased terms (including the one and two argument variants from the "),t("RouterLink",{attrs:{to:"/rdf-ex/description-and-graph-dsl.html#description-builder"}},[s._v("description DSL")]),s._v(") on this module, thus limiting your ability to use these names for business functions within this module.")],1)])])}),[],!1,null,null,null);a.default=n.exports}}]);