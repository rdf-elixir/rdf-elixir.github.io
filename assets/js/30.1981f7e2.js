(window.webpackJsonp=window.webpackJsonp||[]).push([[30],{432:function(a,t,s){"use strict";s.r(t);var e=s(33),n=Object(e.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"serializations"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#serializations"}},[a._v("#")]),a._v(" Serializations")]),a._v(" "),s("p",[a._v("The RDF.ex package comes with implementations of the "),s("a",{attrs:{href:"https://www.w3.org/TR/n-triples/",target:"_blank",rel:"noopener noreferrer"}},[a._v("N-Triples"),s("OutboundLink")],1),a._v(", "),s("a",{attrs:{href:"https://www.w3.org/TR/n-quads/",target:"_blank",rel:"noopener noreferrer"}},[a._v("N-Quads"),s("OutboundLink")],1),a._v(", "),s("a",{attrs:{href:"https://www.w3.org/TR/turtle/",target:"_blank",rel:"noopener noreferrer"}},[a._v("Turtle"),s("OutboundLink")],1),a._v(" and "),s("a",{attrs:{href:"https://www.w3.org/TR/trig/",target:"_blank",rel:"noopener noreferrer"}},[a._v("TriG"),s("OutboundLink")],1),a._v(" serialization formats (incl. the respective RDF-star extensions).\nFormats which require additional dependencies are implemented in separate Hex packages.\nThe "),s("a",{attrs:{href:"http://www.w3.org/TR/json-ld/",target:"_blank",rel:"noopener noreferrer"}},[a._v("JSON-LD"),s("OutboundLink")],1),a._v(" format for example is available with the "),s("a",{attrs:{href:"https://hex.pm/packages/json_ld",target:"_blank",rel:"noopener noreferrer"}},[a._v("JSON-LD.ex"),s("OutboundLink")],1),a._v(" package and the "),s("a",{attrs:{href:"http://www.w3.org/TR/rdf-syntax-grammar/",target:"_blank",rel:"noopener noreferrer"}},[a._v("RDF-XML"),s("OutboundLink")],1),a._v(" format is available with the "),s("a",{attrs:{href:"https://hex.pm/packages/rdf_xml",target:"_blank",rel:"noopener noreferrer"}},[a._v("RDF-XML.ex"),s("OutboundLink")],1),a._v(" package.")]),a._v(" "),s("p",[a._v("RDF graphs and datasets can be read and written to files, strings or streams in a RDF serialization format using the  "),s("code",[a._v("read_file/2")]),a._v(", "),s("code",[a._v("read_string/2")]),a._v(", "),s("code",[a._v("read_stream/2")]),a._v(" and the "),s("code",[a._v("write_file/3")]),a._v(", "),s("code",[a._v("write_string/2")]),a._v(" and "),s("code",[a._v("write_stream/2")]),a._v(" functions of the resp. "),s("code",[a._v("RDF.Serialization.Format")]),a._v(" module.")]),a._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[a._v(":ok")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("NTriples")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("read_file")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"/path/to/some_file.nt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[a._v(":ok")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" nquad_string"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("NQuads")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("write_string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[a._v("TIP")]),a._v(" "),s("p",[s("code",[a._v("use RDF")]),a._v(" defines an "),s("code",[a._v("alias")]),a._v(" for all of the serializations format implemented in RDF.ex, so that you can use them via "),s("code",[a._v("NTriples")]),a._v(", "),s("code",[a._v("NQuads")]),a._v(" and "),s("code",[a._v("Turtle.")])])]),a._v(" "),s("p",[a._v("All of the read and write functions are also available in bang variants which will fail in error cases.")]),a._v(" "),s("p",[a._v("All of these "),s("code",[a._v("read_*")]),a._v(" and "),s("code",[a._v("write_*")]),a._v(" functions are also available in the top-level "),s("code",[a._v("RDF")]),a._v(" module, where the serialization format can be specified in various ways, either by providing the format name via the "),s("code",[a._v("format")]),a._v(" option, or via the "),s("code",[a._v("media_type")]),a._v(" option.")]),a._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[a._v(":ok")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("read_file")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"/path/to/some_file"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[a._v("format:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[a._v(":turtle")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\njson_ld_string "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("write_string!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[a._v("media_type:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"application/ld+json"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("p",[a._v("Note: The later command requires the "),s("code",[a._v("json_ld")]),a._v(" package to be defined as a dependency in the Mixfile of your application.")]),a._v(" "),s("p",[a._v("The file read and write functions are also able to infer the format from the file extension of the given filename.")]),a._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("read_file!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"/path/to/some_file.ttl"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("write_file!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"/path/to/some_file.jsonld"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("h2",{attrs:{id:"streaming"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#streaming"}},[a._v("#")]),a._v(" Streaming")]),a._v(" "),s("p",[a._v("Some of the available serialization formats also provide support for reading serializations from files and writing serializations to streams. At the moment these are the builtin N-Triples and N-Quads formats and the RDF-XML format. For those you have the "),s("code",[a._v("read_stream/2")]),a._v(", "),s("code",[a._v("read_stream!/2")]),a._v("  and "),s("code",[a._v("write_stream/2")]),a._v(" functions available.")]),a._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[a._v("graph "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("XML")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("read_stream!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("xml_stream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\nxml_stream "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("XML")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("write_stream")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("p",[a._v("Note, that there's no "),s("code",[a._v("write_stream!/2")]),a._v(" function. Since it's not possible to determine upfront, if anything will be ok with the stream, "),s("code",[a._v("write_stream/2")]),a._v(" behaves like the other bang variants: It returns the stream directly and errors during consumption of the stream will raise an error.")]),a._v(" "),s("p",[a._v("Many times you'll want read streams from the contents of a file or write streams whose content is written to a file. In these cases you don't have to reach for the stream functions, but can use the file read and write functions instead. For formats with streaming support they use streaming by default, except for "),s("code",[a._v("write_file/3")]),a._v(". For the same reason as above, only "),s("code",[a._v("write_file!/3")]),a._v(" uses streams by default. But you can use the "),s("code",[a._v(":stream")]),a._v(" option to opt-in on "),s("code",[a._v("write_file/3")]),a._v(" or opt-out on the other functions.")]),a._v(" "),s("h2",{attrs:{id:"file-compression"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#file-compression"}},[a._v("#")]),a._v(" File compression")]),a._v(" "),s("p",[a._v("Both file reader and writer functions support a "),s("code",[a._v("gzip")]),a._v(" option which allows to read and write from and to gzip'ed files directly.")]),a._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("NTriples")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("read_file!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"/path/to/some_file.nt.gz"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("XML")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("write_file!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"/path/to/some_file.rdf.gz"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("p",[a._v("This feature can also be combined with file access via streams.")]),a._v(" "),s("h2",{attrs:{id:"base-iri"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#base-iri"}},[a._v("#")]),a._v(" Base IRI")]),a._v(" "),s("p",[a._v("For serialization formats which support it, you can provide a base IRI on the read functions with the "),s("code",[a._v("base_iri")]),a._v(" option. If you don't pass it, the base IRI associated with the serialized graph is used. This is automatically set on deserialization to the one used in serialization or you set it on the graph with the "),s("code",[a._v("RDF.Graph.set_base_iri/2")]),a._v(" function, which also also accepts "),s("a",{attrs:{href:"/rdf-ex/namespaces"}},[s("code",[a._v("RDF.Vocabulary.Namespace")]),a._v(" modules")]),a._v(".")]),a._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[a._v("graph\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("Graph")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("set_base_iri")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("EX")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("p",[a._v("You can also provide a default base IRI in your application configuration, which will be used when no base IRI is given as an option or is set on the graph.")]),a._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[a._v("config "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[a._v(":rdf")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[a._v("default_base_iri:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"http://my_app.example/"')]),a._v("\n")])])]),s("h2",{attrs:{id:"managing-prefixes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#managing-prefixes"}},[a._v("#")]),a._v(" Managing prefixes")]),a._v(" "),s("p",[a._v("The prefixes used in serialization formats which support this can be managed in various ways.")]),a._v(" "),s("p",[a._v("An "),s("code",[a._v("RDF.Graph")]),a._v(" contains a mapping of prefixes to IRI namespaces.\nYou can add prefixes with "),s("code",[a._v("RDF.Graph.add_prefixes/2")]),a._v(".\nThe mapping can given as a map or keyword lists, where the prefixes might be given as atoms or strings, while the IRI namespaces can be given as "),s("code",[a._v("RDF.IRI")]),a._v("s, strings or as "),s("code",[a._v("RDF.Vocabulary.Namespace")]),a._v(" modules. You can use any combinations of these different types, prefixes are stored internally always as atoms and IRI namespaces always as "),s("code",[a._v("RDF.IRI")]),a._v("s.")]),a._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[a._v("graph\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("Graph")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("add_prefixes")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token attr-name"}},[a._v("ex:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("EX")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[a._v("schema:")]),a._v(" ~"),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("I")]),a._v("<"),s("span",{pre:!0,attrs:{class:"token attr-name"}},[a._v("http:")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v("schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("org"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v(">"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("Graph")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("add_prefixes")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"ex2"')]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"http://example2.com/"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("p",[a._v("A single prefix or a list of multiple prefixes can be deleted with "),s("code",[a._v("RDF.Graph.delete_prefixes/2")]),a._v(".")]),a._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[a._v("graph\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("Graph")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("delete_prefixes")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"ex"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token module class-name"}},[a._v("Graph")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("delete_prefixes")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[a._v(":ex2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[a._v(":schema")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("p",[a._v("When a graph is read from such serialization format the deserialized prefixes are automatically stored in the "),s("code",[a._v("RDF.Graph")]),a._v(" structure.")]),a._v(" "),s("p",[a._v("Writing a RDF data structure gives you more options for which prefixes should be serialized:")]),a._v(" "),s("ol",[s("li",[a._v("The "),s("code",[a._v("prefixes")]),a._v(" option of the "),s("code",[a._v("write_*")]),a._v(" functions can be used provide prefix mappings in all the different ways mentionend above and always have the highest precedence.")]),a._v(" "),s("li",[a._v("If the RDF data to be serialized is given as a "),s("code",[a._v("RDF.Graph")]),a._v(" with defined "),s("code",[a._v("prefixes")]),a._v(" these are used, when no prefixes are given with "),s("code",[a._v("prefixes")]),a._v(" option otherwise.")]),a._v(" "),s("li",[a._v("As a fallback when prefixes are not defined in these ways the "),s("code",[a._v("RDF.default_prefixes/0")]),a._v(" are used. You can configure these with the "),s("code",[a._v("default_prefixes")]),a._v(" compile-time configuration in your "),s("code",[a._v("confix.exs")]),a._v(" files:")])]),a._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[a._v("config "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[a._v(":rdf")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[a._v("default_prefixes:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("%")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[a._v("ex:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"http://example.com/"')]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])])]),s("ol",{attrs:{start:"4"}},[s("li",[a._v("The "),s("code",[a._v("RDF.default_prefixes/0")]),a._v(" always contain the "),s("code",[a._v("RDF.standard_prefixes/0")]),a._v(" consisting of prefixes the usual "),s("code",[a._v("xsd")]),a._v(", "),s("code",[a._v("rdf")]),a._v(" and "),s("code",[a._v("rdfs")]),a._v(" prefixes. If you don't want to use these "),s("code",[a._v("RDF.standard_prefixes/0")]),a._v(" for your "),s("code",[a._v("default_prefixes")]),a._v(" you'll explicitly have to disable them with the "),s("code",[a._v("use_standard_prefixes")]),a._v(" compile-time configuration option.")])]),a._v(" "),s("div",{staticClass:"language-elixir extra-class"},[s("pre",{pre:!0,attrs:{class:"language-elixir"}},[s("code",[a._v("config "),s("span",{pre:!0,attrs:{class:"token atom symbol"}},[a._v(":rdf")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[a._v("use_standard_prefixes:")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("false")]),a._v("\n")])])])])}),[],!1,null,null,null);t.default=n.exports}}]);