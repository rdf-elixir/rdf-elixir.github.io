(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{416:function(t,e,a){"use strict";a.r(e);var s=a(33),n=Object(s.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"entities"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#entities"}},[t._v("#")]),t._v(" Entities")]),t._v(" "),a("p",[t._v("The basic concepts of Grax are entities, properties and instances of mappings.\n[Old: The basic concepts of Grax are schemas, properties and mappings.]")]),t._v(" "),a("p",[t._v("A "),a("strong",[t._v("entity")]),t._v(" in Grax is a domain entity of your application, ..., which we would like to represent as an ordinary Elixir struct with the fields for the data we have about the particular entities. But our structs of plain Elixir values should be fully mappable to RDF. As a bidirectionally mapping between\nthe nodes of an RDF graph and "),a("code",[t._v("Grax.Entity")]),t._v(" structs.")]),t._v(" "),a("p",[t._v("We'll need three things:")]),t._v(" "),a("ol",[a("li",[t._v("a field on every "),a("code",[t._v("Grax.Entity")]),t._v(" struct with the URI of the RDF resource representation of an entity of our application,")]),t._v(" "),a("li",[t._v("a bidirectional mapping of the field names of "),a("code",[t._v("Grax.Entity")]),t._v(" structs to URIs for the RDF properties of an entity of our application,")]),t._v(" "),a("li",[t._v("a bidirectional mapping for the different values the fields of a "),a("code",[t._v("Grax.Entity")]),t._v(" struct might have to nodes of an RDF graph.")])]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("Grax.Entity")]),t._v(" struct for a class of entities of our application, together with the specification of the properties these entities will have, are called "),a("strong",[t._v("entity schemas")]),t._v(". If you're familiar with the most wieldly used relational data mapper in Elixir, you can think of them as "),a("code",[t._v("Ecto.Schema")]),t._v("s.")]),t._v(" "),a("p",[t._v('As opposed to the term "field" used for the elements of Elixir structs (or '),a("code",[t._v("Ecto.Schema")]),t._v("s), we are calling the elements of "),a("code",[t._v("Grax.Entity")]),t._v(" struct "),a("strong",[a("em",[t._v("properties")])]),t._v(". [TODO: But they are still implemented on top of ordinary Elixir structs and behave consistent with these and you can even have plain old field names with just an optional default value. But the capability to be mapped between RDF are only available for the subset of the fields for which a mapping to RDF property URIs is defined.]")]),t._v(" "),a("p",[t._v("So, the elements of our "),a("code",[t._v("Grax.Entity")]),t._v(" structs are RDF-mappable properties. Let's see how this looks in practice. A "),a("code",[t._v("Grax.Entity")]),t._v(" struct is defined on a module by using "),a("code",[t._v("Soma.Entity")]),t._v(" module and the "),a("code",[t._v("schema")]),t._v(" macro it imports.")]),t._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Example")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Grax")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Entity")]),t._v("\n\n  schema "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" ~"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("I")]),t._v("<"),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("http:")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("example"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("property"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),a("p",[t._v("A "),a("code",[t._v("Grax.Entity")]),t._v(" schema is defined by a set of field names with optional defaults, just like fields of an ordinary struct and a mapping of these names to RDF property URIs in a block of the "),a("code",[t._v("schema")]),t._v(" macros, providing additional macros, such as the "),a("code",[t._v("propery")]),t._v(" macro for the definition of the different types of fields we can have on")]),t._v(" "),a("p",[t._v("We will call the particular instances of the "),a("code",[t._v("Grax.Entity")]),t._v(" structs "),a("strong",[a("em",[t._v("instance entities")])]),t._v(". The instance entities the individual "),a("code",[t._v("Grax.Entity")]),t._v(" structs with individual mapped Elixir values for/from the RDF description of an individual RDF resource.")]),t._v(" "),a("p",[t._v("You can create Grax mappings by either loading values from a RDF graph or by creating the values on scratch from Elixir values and want to map them later to RDF graphs (more on that in the last section about the Grax API).")]),t._v(" "),a("hr"),t._v(" "),a("hr"),t._v(" "),a("p",[t._v("In order to work with the business logic we are implementing, the data in our "),a("code",[t._v("Grax.Entity")]),t._v(" structs must be conformant with an expected schema in order to be considered valid input data for our application. However, in Grax the types are optional, just as RDF is at its core a schema-free data model with optional types later on. But in order to be mappable to RDF we'll always need to capture the RDF URIs of the properties in a Grax schema.")]),t._v(" "),a("p",[t._v("As an example, let's assume we have a RDF graph like this, which we want to map to Elixir structs with Elixir values for an Elixir application:")]),t._v(" "),a("p",[t._v("TODO: Replace this with a syntax highlighted image!")]),t._v(" "),a("div",{staticClass:"language-ttl extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('@prefix : <http://example.com/> .\n@prefix schema: <https://schema.org/> .\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n\n:User1 \n    a schema:Person, :PremiumUser ;\n    schema:name "Jane" ;\n    schema:email "jane@example.com", "jane@work.com" ;\n    foaf:age 30 ;\n    schema:address [\n      schema:addressCountry "de"\n      schema:addressLocality "Berlin"\n    ] .\n\n:Post1\n    schema:name "Lorem" ;\n    schema:author :User1 ;\n    schema:articleBody """Lorem ipsum dolor sit amet, consectetur adipisicing elit. Provident, nihil, dignissimos. Nesciunt aut totam eius. Magnam quaerat modi vel sed, ipsam atque rem, eos vero ducimus beatae harum explicabo labore!""" .\n')])])]),a("p",[t._v("A Grax schema struct for the "),a("code",[t._v("User")]),t._v(" model of an application could be defined like this by using the "),a("code",[t._v("Grax.Schema")]),t._v(" module and the "),a("code",[t._v("schema")]),t._v(" macro it provides.")]),t._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("User")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Grax")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Schema")]),t._v("\n\n  schema "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ...")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("We'll constantly use terms from "),a("a",{attrs:{href:""}},[t._v("RDF.ex vocabulary namespaces")]),t._v(" instead of RDF URIs in this guide, so you'll might need a little refresher for this way of RDF.ex to express RDF URIs ...")])]),t._v(" "),a("p",[t._v("This will define a struct on the "),a("code",[t._v("User")]),t._v(" module. But this struct wouldn't have any fields for the domain model of our application.")]),t._v(" "),a("p",[t._v("Nevertheless, this could already represent a RDF resource/graph node, since every "),a("code",[t._v("Grax.Schema")]),t._v(" struct has an additional internal field similar to the internal "),a("code",[t._v("__struct__")]),t._v(" field of Elixir structs: a "),a("code",[t._v("__id__")]),t._v(" field, which contains the "),a("code",[t._v("RDF.IRI")]),t._v(" or "),a("code",[t._v("RDF.BlankNode")]),t._v(" of a resource. This additional "),a("code",[t._v("__id__")]),t._v(" field of the struct is the only external difference of a "),a("code",[t._v("Grax.Schema")]),t._v(" from a usual Elixir struct. You should treat it similarly as the internal "),a("code",[t._v("__struct__")]),t._v(" field of any Elixir struct: use it maybe for pattern matching, but don't touch it directly, other than via functions.")]),t._v(" "),a("p",[t._v("TODO: This is the only point where you have deal with RDF-peculiarities in Grax for now: you'll have to provide a URI for the entity you want to create or request. But you won't see any other relicts of the RDF-representation when working with the "),a("code",[t._v("Grax.Entity")]),t._v(" structs further on.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("schema")]),t._v(" macro can be considered equal to a "),a("code",[t._v("defstruct")]),t._v(" in that it allows to define every struct which can be defined with it. Under the hood it will produce the "),a("code",[t._v("defstruct")]),t._v(" call as the first line of the generated code, which means you can use all types of annotations before the "),a("code",[t._v("schema")]),t._v(" macro that can be used before a "),a("code",[t._v("defstruct")]),t._v(", eg. "),a("code",[t._v("@derive")]),t._v(" annotations etc.")])]),t._v(" "),a("p",[t._v("But without any fields with Elixir mappings of the RDF descriptions this isn't very interesting.")]),t._v(" "),a("h2",{attrs:{id:"properties"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#properties"}},[t._v("#")]),t._v(" Properties")]),t._v(" "),a("p",[t._v("A Grax schema consists of a number property declarations inside of a "),a("code",[t._v("schema")]),t._v(" block with two kinds of properties:")]),t._v(" "),a("ol",[a("li",[a("strong",[a("em",[t._v("data properties")])]),t._v(" whose object values we want to map to simple Elixir values and")]),t._v(" "),a("li",[a("strong",[a("em",[t._v("link properties")])]),t._v(" (also called "),a("em",[t._v("object properties")]),t._v("), whose IRI or blank node values should be mapped to recursively nested "),a("code",[t._v("Grax.Schema")]),t._v(" structs.\n(But from the perspective of the struct, with link properties mapped essentially to just a special case of these data properties, link properties are still ordinary fields of an Elixir struct.)")])]),t._v(" "),a("p",[t._v("But let's look at the mapping of data properties first and leave the mapping of link properties for the next section. If we focus for now on the data properties of the user from our example, our statements form a RDF graph of the description of "),a("code",[t._v("EX.User1")]),t._v(" like this:")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/user1-rdf.png",alt:"img"}})]),t._v(" "),a("p",[t._v("Let's make a few transformations of our RDF description and see how we can reach a suitable form for an Elixir representation. First, let's replace the property URIs on the edge labels with atom names we will use as field names of our "),a("code",[t._v("Grax.Schema")]),t._v(" structs, since we don't want to deal with URIs for the properties, but transparently use atom names which are implicitly associated with a "),a("code",[t._v("RDF.IRI")]),t._v(".")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/user1-property-names.png",alt:"img"}})]),t._v(" "),a("p",[t._v("The fields of a "),a("code",[t._v("Grax.Schema")]),t._v(" struct are declared with the "),a("code",[t._v("property/1")]),t._v(" macro in a "),a("code",[t._v("schema")]),t._v(" block. It takes just one argument: a keyword list with specifications of the property, which we'll discuss one by one in the next sections. But the first element in this keyword list is required and has a special meaning. It defines the mapping of an atom name which is used in the application, to a "),a("code",[t._v("RDF.IRI")]),t._v(", which is used in RDF graphs (as opposed to the rest of the "),a("code",[t._v("property/1")]),t._v(" keyword options, which are normal keywords).")]),t._v(" "),a("p",[t._v("So, the key of this first keyword list element will be the name of the field of the struct defined by a "),a("code",[t._v("Grax.Schema")]),t._v(".")]),t._v(" "),a("p",[t._v("The value will be the "),a("code",[t._v("RDF.IRI")]),t._v(" of this property and can be given in any form the "),a("code",[t._v("RDF.IRI.new/1")]),t._v(" constructor of RDF.ex can create IRIs from, including IRIs directly (eg. via IRI sigils), strings or terms from a RDF.ex vocabulary namespace.")]),t._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("User")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Grax")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Schema")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("NS")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),t._v("\n\n  schema "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),a("p",[t._v("This is the minimal form of a property declaration, with no further property specifications. The property is accessible as a usual field name of the struct, but has an exact RDF interpretation through the mapping to a RDF property identifier.")]),t._v(" "),a("p",[t._v("Our struct now consists of two fields "),a("code",[t._v("%User{__id__: id, name: name}")]),t._v(".")]),t._v(" "),a("h2",{attrs:{id:"datatypes"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#datatypes"}},[t._v("#")]),t._v(" Datatypes")]),t._v(" "),a("p",[t._v("In the next step we want to get rid of the RDF literal values and map them to plain Elixir values.")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/user1-datatypes.png",alt:"img"}})]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("type")]),t._v(" specification allows to define the datatype that a data property value should have and which RDF datatype the produced literals for the RDF property should have.")]),t._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("User")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Grax")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Schema")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("NS")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("FOAF")]),t._v("\n\n  schema "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("FOAF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":byte")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),a("p",[t._v("The types are given as atoms which correspond to the respective RDF.ex literal datatypes:")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("Grax datatype")]),t._v(" "),a("th",[t._v("RDF.ex literal datatype")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("code",[t._v(":any_uri")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.AnyURI")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":base64_binary")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.Base64Binary")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":boolean")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.Boolean")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":byte")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.Byte")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":date")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.Date")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":date_time")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.DateTime")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":decimal")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.Decimal")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":double")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.Double")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":float")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.Float")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":int")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.Int")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":integer")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.Integer")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":long")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.Long")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":negative_integer")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.NegativeInteger")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":non_negative_integer")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.NonNegativeInteger")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":non_positive_integer")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.NonPositiveInteger")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":positive_integer")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.PositiveInteger")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":short")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.Short")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":string")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.String")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":time")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.Time")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":unsigned_byte")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.UnsignedByte")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":unsigned_int")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.UnsignedInt")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":unsigned_long")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.UnsignedLong")])])]),t._v(" "),a("tr",[a("td",[a("code",[t._v(":unsigned_short")])]),t._v(" "),a("td",[a("code",[t._v("RDF.XSD.UnsignedShort")])])])])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("The XSD date and time datatypes support also optional timezones, which are not supported by Elixir's "),a("code",[t._v("Date")]),t._v(" and "),a("code",[t._v("Time")]),t._v(" structs. Such date and time values with timezones are represented as tuples consisting of the "),a("code",[t._v("Date")]),t._v(" and "),a("code",[t._v("Time")]),t._v(" struct value and a string with the timezone, such as "),a("code",[t._v('{~D[2020-12-24], "+01:00"}')]),t._v(" or "),a("code",[t._v('{~T[00:00:00], "Z"}')]),t._v(".")])]),t._v(" "),a("p",[t._v("Above these there are a couple of special datatypes:")]),t._v(" "),a("ul",[a("li",[t._v("The "),a("code",[t._v(":any")]),t._v(" datatype (which is the default when no datatype is specified  with the "),a("code",[t._v(":type")]),t._v(' option) means the property can contain values of any datatype. The datatype mapping from Elixir values to XSD datatypes as described in the table in the "Typed Literal" section '),a("RouterLink",{attrs:{to:"/rdf-ex/literals.html#typed-literals"}},[t._v("here")]),t._v(" is applied in this case.")],1),t._v(" "),a("li",[t._v("The "),a("code",[t._v(":numeric")]),t._v(" datatype behaves similar to the "),a("code",[t._v(":any")]),t._v(" datatype, but limits the values to those of numeric datatypes.")]),t._v(" "),a("li",[t._v("The "),a("code",[t._v(":iri")]),t._v(" datatype can be used if IRIs should be kept as they are, which is useful when they shouldn't be mapped to nested mapping structs (described in the next section on links).")])]),t._v(" "),a("h2",{attrs:{id:"values-vs-value-sets"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#values-vs-value-sets"}},[t._v("#")]),t._v(" Values vs. value sets")]),t._v(" "),a("p",[t._v("Finally, we have to solve the problem for how multiple occurrences of the same property in predicates of statements should be handled. This is done by combining all objects for a property of a subject into a list (with set semantics).")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/user1-value-sets.png",alt:"img"}})]),t._v(" "),a("p",[t._v("By default it is assumed that the value of every property is unique, unless specified otherwise. If multiple values should be allowed, the specified datatype on the "),a("code",[t._v(":type")]),t._v(" option must be put in square brackets. The values will then be kept in a list. If you want to specify that a property can have multiple values of any datatype you can do so with "),a("code",[t._v("[:any]")]),t._v(" or "),a("code",[t._v("[]")]),t._v(".")]),t._v(" "),a("p",[t._v("With that we can extend our example mapping schema like this:")]),t._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("User")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Grax")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("NS")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("FOAF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("FOAF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),a("p",[t._v("Finally, we can see how real mapping of our example looks:")]),t._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("User")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("__id__:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("iri")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("EX")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("User1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Jane"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("emails:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jane@example.com"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jane@work.com"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("h2",{attrs:{id:"default-values"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#default-values"}},[t._v("#")]),t._v(" Default values")]),t._v(" "),a("p",[t._v("Default values for the data properties can be defined with the "),a("code",[t._v(":default")]),t._v(" option. It's value is used as the default value of Elixir struct. (Therefore default values can also be defined on virtual properties.)")]),t._v(" "),a("p",[t._v("If not specified otherwise, the default value will be "),a("code",[t._v("nil")]),t._v(", just like the default value on any Elixir struct, for single value properties. But for properties with multiple values it will be the empty list by default.")]),t._v(" "),a("p",[t._v("Generally, if a "),a("code",[t._v(":type")]),t._v(" is defined, the "),a("code",[t._v(":default")]),t._v(" value must match this datatype. Otherwise it won't compile.")]),t._v(" "),a("h2",{attrs:{id:"required-properties"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#required-properties"}},[t._v("#")]),t._v(" Required properties")]),t._v(" "),a("p",[t._v("If you want to specify that a value for a property must be present, you can do so with the "),a("code",[t._v(":required")]),t._v(" option, which defaults to "),a("code",[t._v("false")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("User")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Grax")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("NS")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("FOAF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("email:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("FOAF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),a("h2",{attrs:{id:"virtual-properties"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#virtual-properties"}},[t._v("#")]),t._v(" Virtual properties")]),t._v(" "),a("p",[t._v("Virtual properties are additional fields on the Elixir struct of a "),a("code",[t._v("Grax.Schema")]),t._v(", which have no correspondence in the mapped RDF graph data. They can be defined by setting "),a("code",[t._v("nil")]),t._v(" as the value for the mapped IRI on the second argument position of the "),a("code",[t._v("property/3")]),t._v(" macro.")]),t._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("User")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Grax")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("NS")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("FOAF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("email:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("FOAF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("password:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),a("p",[t._v("Note, that virtual properties don't support the "),a("code",[t._v(":type")]),t._v(" and "),a("code",[t._v(":required")]),t._v(" options of the "),a("code",[t._v("property/3")]),t._v(" macro. (They are also not supported on the "),a("code",[t._v("link/3")]),t._v(" macro described in the next section.) But default values via the "),a("code",[t._v(":default")]),t._v(" option are also supported for virtual properties, since the default value of a "),a("code",[t._v("Grax.Schema")]),t._v(" is just the default value in the Elixir struct.")]),t._v(" "),a("p",[t._v("Virtual properties are an essential part of the solution to allow interchangeable usage instead of plain old Elixir structs. If you already have or want to define fields on the struct you define them as virtual properties on a "),a("code",[t._v("Grax.Schema")]),t._v(".")]),t._v(" "),a("h2",{attrs:{id:"class-declarations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#class-declarations"}},[t._v("#")]),t._v(" Class declarations")]),t._v(" "),a("p",[t._v("You can optionally specify that the instances of a "),a("code",[t._v("Grax.Schema")]),t._v(" [(TODO: mappings)]should be instances of RDFS class by providing its IRI as an argument of the "),a("code",[t._v("schema")]),t._v(" macro.")]),t._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("User")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Grax")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("NS")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("FOAF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Person")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ...  ")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),a("p",[t._v("For now, the only effect that a class-declaration has is that the mapping to RDF graphs will produce a "),a("code",[t._v("rdf:type")]),t._v(" statement accordingly. In particular it doesn't mean that the RDF description of a resource must include a respective "),a("code",[t._v("rdf:type")]),t._v(" to be loadable into a "),a("code",[t._v("Grax.Schema")]),t._v(" struct.")]),t._v(" "),a("hr"),t._v(" "),a("p",[t._v("TODO: Next version")]),t._v(" "),a("p",[t._v("You can access the class declared on a "),a("code",[t._v("Grax.Schema")]),t._v(" struct with the "),a("code",[t._v("__type__/0")]),t._v(" function on every "),a("code",[t._v("Grax.Schema")]),t._v(" module.")]),t._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[t._v("iex"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("User")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__class__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n~"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("I")]),t._v("<"),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("https:")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Person")]),t._v(">\n")])])]),a("p",[t._v("On "),a("code",[t._v("Grax.Schema")]),t._v(" modules without a class declaration this function will return "),a("code",[t._v("nil")]),t._v(". But you can call it polymorphically and pattern-match to dispatch to different behaviour based on RDFS classes:")]),t._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("fun")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("%")]),t._v("schema_module"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mapping"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" schema_module"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__class__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    ~"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("I")]),t._v("<"),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("https:")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Person")]),t._v("> "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# behaviour for people")]),t._v("\n    ~"),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("I")]),t._v("<"),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("https:")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("schema"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("org"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Agent")]),t._v("> "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# behaviour for people")]),t._v("\n    _ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# generic behaviour")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),a("p",[t._v("But every individual mapping struct also has a "),a("code",[t._v(":__type__")]),t._v(" field with a list of types, which always guaranted to have the "),a("code",[t._v("__class__()")]),t._v(" as the first element, but includes any other value of the "),a("code",[t._v("rdf:type")]),t._v(" property.")]),t._v(" "),a("p",[t._v("That means you'll never have to define a "),a("code",[t._v("property :type, RDF.type()")]),t._v(", ...")]),t._v(" "),a("p",[t._v("But you can and, as you'll see next, it makes sometimes sense to do so,\n(but no necessarily a property with this generic name as this is already provided")]),t._v(" "),a("h2",{attrs:{id:"custom-mappings"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#custom-mappings"}},[t._v("#")]),t._v(" Custom mappings")]),t._v(" "),a("p",[t._v("Sometimes you want to perform more complex or simply non-default transformations when mapping RDF data to and from the Elixir structs of your application. In these cases you can define your own custom mapping functions on the "),a("code",[t._v("Grax.Schema")]),t._v(" module and declare their usage on the "),a("code",[t._v("property")]),t._v(" schema definition with the "),a("code",[t._v(":from_rdf")]),t._v(" and "),a("code",[t._v(":to_rdf")]),t._v(" options and the respective function names.")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("from_rdf")]),t._v(" function must accept three arguments:")]),t._v(" "),a("ol",[a("li",[t._v("The first argument is the list of the actual RDF values for the property for which the custom mapping was called.")]),t._v(" "),a("li",[t._v("The second argument is the "),a("code",[t._v("RDF.Description")]),t._v(" of the mapped resource, which can be used when the mapping depends on other properties of the resource description.")]),t._v(" "),a("li",[t._v("The third argument is whole "),a("code",[t._v("RDF.Graph")]),t._v(" from which the mapping is called, which can be used when the mapping depends on other statements of the graph.")])]),t._v(" "),a("p",[t._v("When a mapping can be performed successfully the mapped value must be returned in an "),a("code",[t._v(":ok")]),t._v(" tuple. Otherwise an "),a("code",[t._v(":error")]),t._v(" tuple with the error must be returned.")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("to_rdf")]),t._v(" function must accept two arguments:")]),t._v(" "),a("ol",[a("li",[t._v("The first argument is the list of the actual values of the property from the struct for which the custom mapping was called.")]),t._v(" "),a("li",[t._v("The second argument is the whole "),a("code",[t._v("Grax")]),t._v(" struct, which can be used when the mapping depends on other properties of it.")])]),t._v(" "),a("p",[t._v("The return value can be either:")]),t._v(" "),a("ul",[a("li",[t._v("a two-element "),a("code",[t._v(":ok")]),t._v(" tuple with the mapped RDF values")]),t._v(" "),a("li",[t._v("a three-element "),a("code",[t._v(":ok")]),t._v(" tuple with the mapped RDF values on second position and a list of additional RDF statements which should be added to the produced graph on the third position (the statements can be given in any form accepted by "),a("code",[t._v("RDF.Graph.add/2")]),t._v(")")]),t._v(" "),a("li",[t._v("an "),a("code",[t._v(":error")]),t._v(" tuple with an error")])]),t._v(" "),a("p",[t._v("For both custom mapping function you can return "),a("code",[t._v("nil")]),t._v(" as a value when no values should be produced by the mapping.")]),t._v(" "),a("div",{staticClass:"language-elixir extra-class"},[a("pre",{pre:!0,attrs:{class:"language-elixir"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("defmodule")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("User")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Grax")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alias")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("NS")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("FOAF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("EX")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  schema "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Person")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("email:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("email"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":string")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("required:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("age:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("FOAF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":integer")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("password:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),t._v("\n    property "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("customer_type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n             "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("from_rdf:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":customer_type_from_rdf")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n             "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("to_rdf:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":customer_type_to_rdf")]),t._v("\n    \n    link "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("friends:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("FOAF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("friend"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("User")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    link "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("posts:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("SchemaOrg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("author"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("Post")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("customer_type_from_rdf")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("types"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _description"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _graph"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":ok")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("RDF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("iri")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("EX")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("PremiumUser")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("in")]),t._v(" types"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("do:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":premium_user")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("customer_type_to_rdf")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":premium_user")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _user"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("do:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":ok")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("EX")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token module class-name"}},[t._v("PremiumUser")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("customer_type_to_rdf")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("do:")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token atom symbol"}},[t._v(":ok")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("nil")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),a("p",[t._v("Note, that if you provide both "),a("code",[t._v("from_rdf")]),t._v(" and "),a("code",[t._v("to_rdf")]),t._v(" functions, you can use any type of value on this property, even ones for which no corresponding datatype is supported. But if the value(s) produced by "),a("code",[t._v("from_rdf")]),t._v(" and kept in the struct is covered by a supported a datatype it can still be useful to specify a "),a("code",[t._v("type")]),t._v(" to benefit from the performed validations.")]),t._v(" "),a("p",[t._v("TODO: Provide another example over the "),a("code",[t._v("schema:email")]),t._v(" property which reduces the emails to a single one ...")])])}),[],!1,null,null,null);e.default=n.exports}}]);