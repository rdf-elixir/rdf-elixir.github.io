(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{423:function(s,a,t){"use strict";t.r(a);var e=t(33),n=Object(e.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"description-and-graph-dsl"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#description-and-graph-dsl"}},[s._v("#")]),s._v(" Description and Graph DSL")]),s._v(" "),t("p",[s._v("RDF.ex comes with a declarative DSL to encode full RDF graphs in Elixir, which allows to serialize RDF graphs with the full power of Elixir and compile-time checks.")]),s._v(" "),t("p",[s._v("It consists of two building-blocks (which can also be used independently of each other):")]),s._v(" "),t("ul",[t("li",[s._v("builder functions for compact "),t("code",[s._v("RDF.Description")]),s._v("s")]),s._v(" "),t("li",[s._v("a general builder function for the encoding of "),t("code",[s._v("RDF.Graph")]),s._v("s")])]),s._v(" "),t("h2",{attrs:{id:"description-builder"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#description-builder"}},[s._v("#")]),s._v(" Description builder")]),s._v(" "),t("p",[s._v("The functions for the properties on a "),t("code",[s._v("RDF.Vocabulary.Namespace")]),s._v(" module, which return the "),t("code",[s._v("RDF.IRI")]),s._v(" of the property (see "),t("a",{attrs:{href:"/rdf-ex/namespaces"}},[s._v("here")]),s._v(" for an introduction to "),t("code",[s._v("RDF.Vocabulary.Namespace")]),s._v("s), are also available in a description builder variant, that accepts a subject and objects as arguments.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("type")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Bar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("p",[s._v("If you want to state multiple statements with the same subject and predicate, you can pass the objects as a list:")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("type")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Bar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Baz")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("foo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Bar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("42")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Baz")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("p",[s._v("The produced statements are returned by this function as a "),t("code",[s._v("RDF.Description")]),s._v(" structure. Since the first argument of these property functions also accept an "),t("code",[s._v("RDF.Description")]),s._v(" for the subject (just using its subject as the subject for newly generated triple), the calls of these functions can be nested easily.\nIn combination with Elixirs pipe operators this leads to a way to describe RDF resources which resembles "),t("a",{attrs:{href:"https://www.w3.org/TR/turtle/",target:"_blank",rel:"noopener noreferrer"}},[s._v("Turtle"),t("OutboundLink")],1),s._v(":")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("type")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Bar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("baz")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("p",[s._v("This will produce this "),t("code",[s._v("RDF.Description")]),s._v(":")]),s._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("#RDF.Description<subject: ~I<http://example.com/Foo>\n  <http://example.com/Foo>\n      a <http://example.com/Bar> ;\n      <http://example.com/baz> 1, 2, 3 .\n>\n")])])]),t("h2",{attrs:{id:"graph-builder"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#graph-builder"}},[s._v("#")]),s._v(" Graph builder")]),s._v(" "),t("p",[s._v("Full RDF graphs can be build with the "),t("code",[s._v("RDF.Graph.build/2")]),s._v(" macro. It uses a "),t("code",[s._v("do")]),s._v(" block in which you can write down RDF triples in any form supported by RDF.ex (including "),t("code",[s._v("RDF.Description")]),s._v("s with the description DSL) or Elixir expressions which return any of these forms.\nThese triples will be added to the created "),t("code",[s._v("RDF.Graph")]),s._v(" the macro returns.")]),s._v(" "),t("p",[s._v("As usual, you'll have to "),t("code",[s._v("require RDF.Graph")]),s._v(" to be able to use the macro or just "),t("code",[s._v("use RDF")]),s._v(".")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alias")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("S")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("P")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("O")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("S2")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("p1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("O2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("p2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  \n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("%")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("S3")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("%")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("p1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("O1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("p2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("O2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("O3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("This will return the following "),t("code",[s._v("RDF.Graph")]),s._v(":")]),s._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("#RDF.Graph<name: nil\n  @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n  @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n  @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n\n  <http://example.org/S>\n      <http://example.org/P> <http://example.org/O> .\n\n  <http://example.org/S2>\n      <http://example.org/p1> <http://example.org/O2> ;\n      <http://example.org/p2> 1, 2, 3 .\n\n  <http://example.org/S3>\n      <http://example.org/p1> <http://example.org/O1> ;\n      <http://example.org/p2> <http://example.org/O2>, <http://example.org/O3> .\n>\n")])])]),t("p",[s._v("Apart from the vocabulary namespaces aliased in the scope of the block, you can use the "),t("code",[s._v("RDF")]),s._v(", "),t("code",[s._v("RDFS")]),s._v(" and "),t("code",[s._v("OWL")]),s._v(" vocabulary namespaces inside of the build block without an explicit alias.\nAlso, RDF sigils are available without an explicit "),t("code",[s._v("import RDF.Sigils")]),s._v(".\nSimilar to the "),t("code",[s._v("a")]),s._v(" keyword in Turtle, an "),t("code",[s._v("a")]),s._v(" alias for the "),t("code",[s._v("RDF.type")]),s._v(" function can be used.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("require")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alias")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Demo")]),s._v(">"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("P")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("L")]),s._v("<literal"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("en"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("OWL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDFS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("description")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"example"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("In order to not pollute the context of the "),t("code",[s._v("build")]),s._v(" caller with these auto-"),t("code",[s._v("alias")]),s._v("es and -"),t("code",[s._v("import")]),s._v("s, the build block is isolated under the hood from the caller context. But this also means variables from the caller context are not available in the build block. If you want to use them in build block, you'll have to rebind the variables in a keyword list as the first argument of the "),t("code",[s._v("build")]),s._v(" call.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),s._v("\n\nfoo "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("42")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("foo:")]),s._v(" foo "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("S")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("p")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" foo"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("The same applies to "),t("code",[s._v("import")]),s._v("s and "),t("code",[s._v("require")]),s._v("s from the caller context. You'll have to re-"),t("code",[s._v("import")]),s._v(" or re-"),t("code",[s._v("require")]),s._v(" them. Aliases from the caller context, however, are all available because they are re-"),t("code",[s._v("alias")]),s._v("ed automatically in the build block.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alias")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Something")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Something is not imported here and needs to be ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# re-imported again to be available")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Something")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# EX is available  ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("S")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("something")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("O")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("In fact, with Elixir versions >= 1.17, aliases inside of the build block are no longer supported, i.e. don't have the desired effect. However, instead of aliasing vocabulary namespaces in the surrounding module, there is a better solution anyway: you can also declare them inside of the build block with a "),t("code",[s._v("@prefix")]),s._v(" definition. This will not only create an alias for the vocabulary namespace in the build block, but adds it as a prefix to the created "),t("code",[s._v("RDF.Graph")]),s._v(". By default, it will use the downcased and underscored name of the vocabulary namespace module (resp. the last segment of its fully qualified name), but you can also define a custom prefix by providing it as the key in a keyword tuple after the "),t("code",[s._v("@prefix")]),s._v(", instead of just defining the vocabulary namespace module.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("require")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FOAF")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("rel:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Rel")]),s._v("\n\n  ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("org"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#green-goblin>")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FOAF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Person")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    \n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Rel")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("enemyOf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("org"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#spiderman>)")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FOAF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Green Goblin"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n  ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("org"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#spiderman>")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FOAF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Person")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Rel")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("enemyOf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("org"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#green-goblin>)")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FOAF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Spiderman"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("L")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Человек-паук"')]),s._v("ru"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("This will build the following "),t("code",[s._v("RDF.Graph")]),s._v(":")]),s._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v('#RDF.Graph<name: nil\n  @prefix foaf: <http://xmlns.com/foaf/0.1/> .\n  @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n  @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n  @prefix rel: <http://www.perceive.net/schemas/relationship/> .\n  @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n\n  <http://example.org/#green-goblin>\n      a foaf:Person ;\n      rel:enemyOf <http://example.org/#spiderman> ;\n      foaf:name "Green Goblin" .\n\n  <http://example.org/#spiderman>\n      a foaf:Person ;\n      rel:enemyOf <http://example.org/#green-goblin> ;\n      foaf:name "Человек-паук"@ru, "Spiderman" .\n>\n')])])]),t("p",[s._v("When you want to use terms from a URI namespace for which you don't have "),t("code",[s._v("RDF.Vocabulary.Namespace")]),s._v(" defined in your application, you can define an ad-hoc namespace in your "),t("code",[s._v("build")]),s._v(" block with a "),t("code",[s._v("@prefix")]),s._v(" definition and a string with the URI namespace. In that case you must also provide the prefix to be used. The name for the generated ad-hoc vocabulary namespace will be the upper-cased version of the prefix.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("ex:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://example.com/ad-hoc/"')]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Ex")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("S")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Ex")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("p")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Ex")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("O")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("This will result in the following "),t("code",[s._v("RDF.Graph")]),s._v(":")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#RDF.Graph<name: nil")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("ex:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("example"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("ad"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("hoc"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("> "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("rdf:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1999")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("02")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("syntax"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("ns"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#> .")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("rdfs:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("rdf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("schema"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#> .")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("xsd:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("http:")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("w3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("org")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2001")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("XMLSchema")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#> .")]),s._v("\n\n  ex"),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":S")]),s._v("\n      ex"),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":p")]),s._v(" ex"),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":O")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n")])])]),t("div",{staticClass:"custom-block warning"},[t("p",{staticClass:"custom-block-title"},[s._v("WARNING")]),s._v(" "),t("p",[s._v("Unfortunately, for Elixir versions < 1.13 you might encounter undefined-function warnings for uses of lower-cased terms from ad-hoc namespaces defined with such "),t("code",[s._v("@prefix")]),s._v(" definitions.")])]),s._v(" "),t("p",[s._v("The base URI of the "),t("code",[s._v("RDF.Graph")]),s._v(" can be specified with a "),t("code",[s._v("@base")]),s._v(" declaration and the URI as a string, IRI sigil or a vocabulary namespace. With a "),t("code",[s._v("@base")]),s._v(" declaration in place, all IRI sigils in the build block with relative URIs, will be automatically resolved to absolute URIs against the specified base URI.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("require")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@base")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FOAF")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Rel")]),s._v("\n  \n  ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#green-goblin>")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FOAF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Person")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    \n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Rel")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("enemyOf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#spiderman>)")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FOAF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Green Goblin"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n  ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#spiderman>")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FOAF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Person")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Rel")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("enemyOf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("I")]),s._v("<"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#green-goblin>)")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("FOAF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Spiderman"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ~"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("L")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Человек-паук"')]),s._v("ru"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("Now, we're building this "),t("code",[s._v("RDF.Graph")]),s._v(":")]),s._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v('#RDF.Graph<name: nil\n  @base <http://example.org/> .\n\n  @prefix foaf: <http://xmlns.com/foaf/0.1/> .\n  @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n  @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n  @prefix rel: <http://www.perceive.net/schemas/relationship/> .\n  @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n\n  <#green-goblin>\n      a foaf:Person ;\n      rel:enemyOf <#spiderman> ;\n      foaf:name "Green Goblin" .\n\n  <#spiderman>\n      a foaf:Person ;\n      rel:enemyOf <#green-goblin> ;\n      foaf:name "Человек-паук"@ru, "Spiderman" .\n>\n')])])]),t("p",[s._v("So far, all examples have shown fixed triple structures only, but the build blocks can include any Elixir expression, as long it returns RDF data in any of the forms supported by RDF.ex.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("file:")]),s._v(" file"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("args:")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("rank:")]),s._v(" rank "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@base")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://chess.example.com/"')]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("ExampleModule")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("function_returning_rdf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Enum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("map")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("..")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("S")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("p")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token argument variable"}},[s._v("&1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" file "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<-")]),s._v(" ?a"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("..")]),s._v("?h"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" rank "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<-")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("..")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n    ~i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("##{file}#{rank}>")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Chess")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Square")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("If an expression evaluates to "),t("code",[s._v("nil")]),s._v(" or "),t("code",[s._v(":ok")]),s._v(", it will be excluded automatically. This enables the use of conditionals and the use of the logger in your build blocks:")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("args:")]),s._v(" args "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# the nil result in the negative case is ignored")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("someCondition?")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("ExampleModule")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("function_returning_rdf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v(" \n\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("good_data?")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("ExampleModule")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("function_returning_more_rdf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# the :ok value returned by Logger.warn/1 is ignored")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Logger")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("warn")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Bad data was ignored"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("Assignments in build blocks are essentially declarations, as their results are also ignored from the inclusion in the produced graph.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  reusable_value "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("42")]),s._v("\n \n  "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("S1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("p")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("reusable_value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("S2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("p")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("reusable_value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("So, if you assign some RDF data to a variable and want to include it in the graph, you have to evaluate the assigned variable explicitly.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  triple "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("S")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("p")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("O")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  triple\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("The fact that assignments are not added to the graph, allows you to use them to ignore an expression in a build block, which does return something you don't want to include in the built RDF graph.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("args:")]),s._v(" args "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  _ "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("function_with_side_effects")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("ExampleModule")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("function_returning_rdf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("Note that the assignments are still pattern matches, so they can be used as validation guards.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("args:")]),s._v(" args "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token atom symbol"}},[s._v(":ok")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" _"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("function_with_side_effects")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("ExampleModule")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("function_returning_rdf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("Finally, you can also exclude the result of an expression from inclusion in the built RDF graph more explicitly, by prepending it with the "),t("code",[s._v("exclude")]),s._v(" function.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("args:")]),s._v(" args "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  exclude "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("function_with_side_effects")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("ExampleModule")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("function_returning_rdf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("The "),t("code",[s._v("RDF.Graph.build/2")]),s._v(" function also accepts all options available on "),t("code",[s._v("RDF.Graph.new/2")]),s._v(" as the second argument, which it will use to create the initial "),t("code",[s._v("RDF.Graph")]),s._v(" to which the triples in the build block are added. The "),t("code",[s._v("@prefix")]),s._v("es and "),t("code",[s._v("@base")]),s._v(" URI declared within the build block will overwrite the ones from "),t("code",[s._v(":prefixes")]),s._v(" and "),t("code",[s._v(":base")]),s._v(" keyword options.")]),s._v(" "),t("div",{staticClass:"language-elixir extra-class"},[t("pre",{pre:!0,attrs:{class:"language-elixir"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("use")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alias")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("NS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),s._v("\n\nopts "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("name:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("GraphName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n  "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("base_iri:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://base_iri/A"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("prefixes:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("ex:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("old")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("other:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("used")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("init:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Foo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Bar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Baz")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("RDF")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("Graph")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("build "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" opts "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@base")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"http://base_iri/B"')]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token attribute variable"}},[s._v("@prefix")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token attr-name"}},[s._v("ex:")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("S")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("p")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("EX")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token module class-name"}},[s._v("O")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("\n")])])]),t("p",[s._v("This will build this graph:")]),s._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("#RDF.Graph<name: ~I<http://example.org/GraphName>\n  @base <http://base_iri/B> .\n\n  @prefix ex: <http://example.org/> .\n  @prefix other: <http://example.org/used> .\n\n  ex:Foo\n      ex:Bar ex:Baz .\n\n  ex:S\n      ex:p ex:O .\n>\n")])])]),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),t("p",[s._v("Providing an existing graph on the "),t("code",[s._v(":init")]),s._v(" opt is the shortest way to use "),t("code",[s._v("build")]),s._v(" for adding statements to an existing graph.")])])])}),[],!1,null,null,null);a.default=n.exports}}]);